{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b52de5-f42e-4634-aac7-2a5c988ca4e2",
   "metadata": {},
   "source": [
    "# Giving the AI Tools: Interacting with External Information and Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768ca47-0b06-43a9-893c-1eb1562296d3",
   "metadata": {},
   "source": [
    "#### Generative AI models are powerful, but they have limitations. \n",
    "* They have a knowledge cut-off (they don't know about the absolute latest events)\n",
    "* They can't perform complex calculations perfectly\n",
    "* They can't directly interact with external systems like databases or APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418d9db-4f19-4f2a-8560-847844be0599",
   "metadata": {},
   "source": [
    "#### This is where Tools come in. By defining specific functions (tools) that your code can execute, you can empower the AI to:\n",
    "* Access up-to-date information: Look up current weather, stock prices, news, definitions, etc.\n",
    "* Perform accurate calculations: Use a calculator for reliable math.\n",
    "* Interact with services: Send emails, set reminders, query databases (with appropriate setup).\n",
    "* Retrieve specific knowledge: Look up information in internal documents or databases (a common pattern called RAG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1ed211-50ab-4bed-8075-b0d586641044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e0998-4442-436a-b94a-0ad7f9463b95",
   "metadata": {},
   "source": [
    "#### Display Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1254d56-ff1b-46ff-aa36-df948d27d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # Import json for pretty printing function call arguments\n",
    "\n",
    "def display_response(response: genai.types.GenerateContentResponse):\n",
    "    if response is None:\n",
    "        print(\"Received an empty or None response.\")\n",
    "        return\n",
    "\n",
    "    # A response can contain one or more 'parts'.\n",
    "    # These parts can be text, function calls, etc.\n",
    "    if response.parts:\n",
    "        print(\"Content Parts:\")\n",
    "        for i, part in enumerate(response.parts):\n",
    "            print(f\"  Part {i+1}:\")\n",
    "            if part.text:\n",
    "                print(f\"    Type: Text\")\n",
    "                print(\"    Content:\")\n",
    "                print(\"      \" + part.text.replace('\\n', '\\n      '))\n",
    "            elif part.function_call:\n",
    "                print(f\"    Type: Function Call Request\")\n",
    "                print(f\"    Name: {part.function_call.name}\")\n",
    "            else:\n",
    "                print(f\"    Type: Unknown/Other Part Type\")\n",
    "                print(f\"    Raw Part Data: {part}\")\n",
    "\n",
    "    elif not response.parts:\n",
    "         print(\"Response contains no content parts.\")\n",
    "         if response.prompt_feedback:\n",
    "             print(\"Prompt Feedback:\")\n",
    "             print(response.prompt_feedback)\n",
    "\n",
    "    print(\"----------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d0473-7731-446c-b55e-a48a37c2e54f",
   "metadata": {},
   "source": [
    "#### Define your tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35214f9-78b8-46df-903d-0a94b0698a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai.types as genai_types # Need this for ToolConfig\n",
    "import os\n",
    "\n",
    "\n",
    "weather_tool = genai.protos.Tool(\n",
    "    function_declarations=[\n",
    "        genai.protos.FunctionDeclaration(\n",
    "            name='get_weather',\n",
    "            description='Gets the current weather conditions for a specific location.',\n",
    "            parameters=genai.protos.Schema(\n",
    "                type=\"OBJECT\", \n",
    "                properties={\n",
    "                    'location': genai.protos.Schema(type=\"STRING\", description='The city and state or country, e.g. \"San Francisco, CA\" or \"London, UK\"'), \n",
    "                },\n",
    "                required=['location'],\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "definition_tool = genai.protos.Tool(\n",
    "    function_declarations=[\n",
    "        genai.protos.FunctionDeclaration(\n",
    "            name='lookup_definition',\n",
    "            description='Looks up the definition of a given word.',\n",
    "            parameters=genai.protos.Schema(\n",
    "                type=\"OBJECT\", \n",
    "                properties={\n",
    "                    'word': genai.protos.Schema(type=\"STRING\", description='The word to look up.'), \n",
    "                },\n",
    "                required=['word'],\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine the tools you want this model instance to use\n",
    "available_tools = [weather_tool, definition_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48faea7f-3796-4cc1-bf72-e19213bada1d",
   "metadata": {},
   "source": [
    "#### Initialize the model *with* the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6226de5-51d0-435f-8eda-d6fbd40cc92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with tools.\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    'models/gemini-2.0-flash',\n",
    "    tools=available_tools, \n",
    ")\n",
    "\n",
    "print(\"Model initialized with tools.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a70696-645e-4975-80ba-1c934e6c2882",
   "metadata": {},
   "source": [
    "#### Helper function to execute tool calls (basic simulation for demo)\n",
    "In a real application, this would be more robust and handle errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c1cf6e-c3e6-40c6-93ae-43f6b1b313a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool_call(function_call):\n",
    "    tool_name = function_call.name\n",
    "    args = function_call.args\n",
    "\n",
    "    print(f\"Executing tool: {tool_name} with args: {args}\")\n",
    "\n",
    "    # --- Define your tool execution logic here ---\n",
    "    if tool_name == \"get_weather\":\n",
    "        location = args.get(\"location\", \"unknown\")\n",
    "        # Simulate an API call - in reality, call a weather API\n",
    "        if \"london\" in location.lower():\n",
    "            return {\"temperature\": \"15째C\", \"conditions\": \"Cloudy\"}\n",
    "        elif \"new york\" in location.lower():\n",
    "             return {\"temperature\": \"22째C\", \"conditions\": \"Sunny\"}\n",
    "        else:\n",
    "             return {\"temperature\": \"N/A\", \"conditions\": \"Location not found\"}\n",
    "    elif tool_name == \"lookup_definition\":\n",
    "         word = args.get(\"word\", \"\")\n",
    "         # Simulate a dictionary lookup\n",
    "         definitions = {\n",
    "             \"ephemeral\": \"lasting for a very short time.\",\n",
    "             \"ubiquitous\": \"present, appearing, or found everywhere.\",\n",
    "             \"serendipity\": \"the occurrence and development of events by chance in a happy or beneficial way.\"\n",
    "         }\n",
    "         return {\"definition\": definitions.get(word.lower(), f\"Definition not found for '{word}'\")}\n",
    "    # ----------------------------------------------\n",
    "\n",
    "    return {\"error\": f\"Tool '{tool_name}' not implemented.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cca94-a088-4cc9-a4cd-e76168c82927",
   "metadata": {},
   "source": [
    "#### Use the initialized model to start the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c20760d-0e3f-4129-ad1e-2cf6a49ff122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending query: 'What is the weather in London?'\n",
      "Content Parts:\n",
      "  Part 1:\n",
      "    Type: Function Call Request\n",
      "    Name: get_weather\n",
      "----------------------\n",
      "\n",
      "Executing tool: get_weather with args: <proto.marshal.collections.maps.MapComposite object at 0x107d47310>\n",
      "Tool execution result: {'temperature': '15째C', 'conditions': 'Cloudy'}\n",
      "Sending tool result back to the model...\n",
      "Content Parts:\n",
      "  Part 1:\n",
      "    Type: Text\n",
      "    Content:\n",
      "      The weather in London, UK is cloudy with a temperature of 15째C.\n",
      "      \n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "convo = model.start_chat()\n",
    "\n",
    "user_query = \"What is the weather in London?\"\n",
    "\n",
    "print(f\"Sending query: '{user_query}'\")\n",
    "\n",
    "# Send the user's query\n",
    "response = convo.send_message(user_query)\n",
    "\n",
    "# Display the immediate response (should be a tool call)\n",
    "display_response(response)\n",
    "\n",
    "# The model predicts the need for a tool and predicts the structure of the function call, \n",
    "#  but it cannot run the function itself.\n",
    "if response.parts and response.parts[0].function_call:\n",
    "    function_call = response.parts[0].function_call\n",
    "\n",
    "    # Execute the function call using the helper function\n",
    "    tool_result = execute_tool_call(function_call)\n",
    "\n",
    "    print(f\"Tool execution result: {tool_result}\")\n",
    "\n",
    "    print(\"Sending tool result back to the model...\")\n",
    "    response_after_tool = convo.send_message(genai.protos.Content(\n",
    "        role='function',\n",
    "        parts=[genai.protos.Part(function_response=genai.protos.FunctionResponse(\n",
    "            name=function_call.name,\n",
    "            response=tool_result\n",
    "        ))]\n",
    "    ))\n",
    "    \n",
    "    # print(f\"response_after_tool: {response_after_tool}\")\n",
    "    # Display the final response\n",
    "    display_response(response_after_tool)\n",
    "else:\n",
    "    print(\"Model did not request a tool.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8fc5e-4196-449b-8ebb-ab61bc47604e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
