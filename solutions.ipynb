{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88f402-f724-4f7e-ad53-237215bda3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"api_key\")\n",
    "\n",
    "\n",
    "def get_completion(prompt):\n",
    "    \"\"\"\n",
    "    Get the completion for a given prompt using the specified model.\n",
    "    Returns the answer with the highest score.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "            \"models/gemini-2.0-flash\",\n",
    "            system_instruction=\"You are a user.\",\n",
    "        )\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ef53202a6af2a",
   "metadata": {},
   "source": [
    "## Reference Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42087e7d54d3a831",
   "metadata": {},
   "source": [
    "For the following text:\n",
    "Needed a nice lamp for my bedroom, and this one had \n",
    "additional storage and not too high of a price point. \n",
    "Got it fast.  The string to our lamp broke during the \n",
    "transit and the company happily sent over a new one. \n",
    "Came within a few days as well. It was easy to put \n",
    "together.  I had a missing part, so I contacted their \n",
    "support and they very quickly got me the missing piece! \n",
    "Lumina seems to me to be a great company that cares \n",
    "about their customers and products!!\n",
    "\n",
    "Validate if this author of this text is happy or not (answer in a single word: Positive/Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f7021-4d25-4efa-92ea-5db2c131b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8765a7cf0f9b3",
   "metadata": {},
   "source": [
    "## Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128bcbc-1354-4b96-adcd-a755a5306ed0",
   "metadata": {},
   "source": [
    "Instruct the AI to write a the best unit test for the following code:\n",
    "```\n",
    "import requests\n",
    "\n",
    "def get_user_data(user_id):\n",
    "    url = f\"https://api.example.com/users/{user_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87757a21-ea81-4f0a-b116-32455a7bda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "import requests\n",
    "\n",
    "def get_user_data(user_id):\n",
    "    url = f\"https://api.example.com/users/{user_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "I have the following code: '''{code}'''. Write a unit test using pytest patch \n",
    "Give a solution using a decorator \n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c92ff6-3511-4b76-9186-f9818639176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534f79d57e6bba2",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31902ed8375c1d",
   "metadata": {},
   "source": [
    "You have a log file (app.log) that contains various events, such as errors, warnings, and informational messages. The goal is to extract key insights like:\n",
    "\t1.\tThe total number of errors.\n",
    "\t2.\tThe most common error message.\n",
    "\t3.\tThe timestamp of the last error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b3d01f17fafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are provided with a log file containing application events. Each line includes a timestamp, a log level (e.g., INFO, ERROR, WARNING), and a message. Your task is to analyze the file and return only the results for the following:\n",
    "1. The total number of entries with the log level `ERROR`.\n",
    "2. The most common error message.\n",
    "3. The timestamp of the last error in the log.\n",
    "\n",
    "Only return the results in this exact format:\n",
    "- Total Errors: <number>\n",
    "- Most Common Error: \"<error message>\"\n",
    "- Last Error Timestamp: <timestamp>\n",
    "\n",
    "Do not provide any Python code or explanations—just the results.\n",
    "\"\"\"\n",
    "\n",
    "log_file_path = \"app.log\"  \n",
    "log_file = genai.upload_file(path=log_file_path, display_name=\"Log Output\")\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")  \n",
    "response = model.generate_content([log_file, prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6c4e56a1620ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Read the log file content\n",
    "with open(\"app.log\", \"r\") as file:\n",
    "    log_content = file.readlines()\n",
    "\n",
    "# Step 1: Parse the log content into a structured format\n",
    "logs = []\n",
    "for line in log_content:\n",
    "    match = re.match(r\"(?P<timestamp>\\S+ \\S+) \\[(?P<level>\\w+)] (?P<message>.+)\", line)\n",
    "    if match:\n",
    "        logs.append(match.groupdict())\n",
    "\n",
    "# Step 2: Convert to DataFrame for analysis\n",
    "df = pd.DataFrame(logs)\n",
    "\n",
    "# Step 3: Filter error logs\n",
    "error_logs = df[df['level'] == 'ERROR']\n",
    "\n",
    "# Step 4: Count total errors\n",
    "total_errors = len(error_logs)\n",
    "\n",
    "# Step 5: Find the most common error message\n",
    "most_common_error = Counter(error_logs['message']).most_common(1)[0][0] if not error_logs.empty else None\n",
    "\n",
    "# Step 6: Find the timestamp of the last error\n",
    "last_error_timestamp = error_logs['timestamp'].iloc[-1] if not error_logs.empty else None\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Errors: {total_errors}\")\n",
    "print(f\"Most Common Error: \\\"{most_common_error}\\\"\")\n",
    "print(f\"Last Error Timestamp: {last_error_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3150a74544b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
