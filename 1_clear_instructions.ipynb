{
 "cells": [
  {
   "cell_type": "code",
   "id": "be02a0f2-c45e-469f-aaac-838434a1b87c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:01:07.730926Z",
     "start_time": "2024-12-01T13:01:07.059073Z"
    }
   },
   "source": [
    "!pip install google-generativeai\n",
    "!pip install langchain-google-genai"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://keren.finkelstein:****@bigpandaio.jfrog.io/artifactory/api/pypi/pypi/simple\r\n",
      "Requirement already satisfied: google-generativeai in ./venv/lib/python3.11/site-packages (0.8.3)\r\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in ./venv/lib/python3.11/site-packages (from google-generativeai) (0.6.10)\r\n",
      "Requirement already satisfied: google-api-core in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.23.0)\r\n",
      "Requirement already satisfied: google-api-python-client in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.154.0)\r\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.36.0)\r\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.11/site-packages (from google-generativeai) (5.29.0)\r\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.10.2)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.11/site-packages (from google-generativeai) (4.12.2)\r\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./venv/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./venv/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.66.0)\r\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in ./venv/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.3)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\r\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in ./venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\r\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.27.1)\r\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\r\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./venv/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "a23cc2ea-26ed-4d05-b70b-2dd75f7836c6",
   "metadata": {},
   "source": [
    "## helper function\n",
    "Throughout this course, we will use Ollama with llama3 model and the chat completions endpoint.\n",
    "\n",
    "This helper function will make it easier to use prompts and look at the generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "id": "2007d355-c874-485f-8edb-1f84e6248950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:09:48.206457Z",
     "start_time": "2024-12-01T13:09:46.549573Z"
    }
   },
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"<your-key>\")\n",
    "\n",
    "\n",
    "def get_completion(prompt):\n",
    "    \"\"\"\n",
    "    Get the completion for a given prompt using the specified model.\n",
    "    Returns the answer with the highest score.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "            \"models/gemini-1.5-flash\",\n",
    "            system_instruction=\"You are a user.\",\n",
    "        )\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "answer = get_completion(prompt)\n",
    "\n",
    "print(answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calling the model using Langchain Google Generative AI",
   "id": "5c30f28f670d4bae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:16:08.366808Z",
     "start_time": "2024-12-07T10:15:54.269146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<your-key>\"\n",
    "\n",
    "# Initialize the Gemini model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "\n",
    "# Define your messages\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Tell me about the benefits of using LangChain with Gemini models.\"),\n",
    "]\n",
    "\n",
    "# Generate a response\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ],
   "id": "eaa013c61deac88c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LangChain with Google's Gemini models offers several key benefits that enhance the development and deployment of powerful language-based applications:\n",
      "\n",
      "**1. Simplified Integration and Abstraction:**\n",
      "\n",
      "* **Easy Access to Gemini's Capabilities:** LangChain provides a clean, standardized interface to interact with Gemini models, abstracting away the complexities of direct API calls and authentication. This simplifies the process of integrating Gemini into your applications.\n",
      "* **Consistent API across Models:**  LangChain allows you to switch between different Gemini models (and even other LLMs) with minimal code changes, promoting flexibility and experimentation.\n",
      "* **Streamlined Workflow:**  LangChain handles the details of prompt construction, model invocation, and response parsing, allowing you to focus on the core logic of your application.\n",
      "\n",
      "**2. Enhanced Prompt Management and Engineering:**\n",
      "\n",
      "* **Structured Prompts:** LangChain facilitates the creation of more complex and dynamic prompts using its templating and chaining capabilities. This allows you to incorporate variables, external data, and intermediate steps into your prompts, leading to more accurate and relevant results.\n",
      "* **Prompt Optimization:** LangChain can assist in experimenting with different prompt variations and evaluating their performance, helping you refine your prompts for optimal results.\n",
      "* **Memory Management:**  For conversational applications, LangChain provides mechanisms to maintain context and history across multiple interactions with the Gemini model, enabling more coherent and engaging conversations.\n",
      "\n",
      "**3. Advanced Application Development:**\n",
      "\n",
      "* **Chains and Pipelines:** LangChain's chain and pipeline functionalities enable you to combine multiple Gemini calls (or other operations) into a sequence, creating sophisticated workflows for tasks like question answering, text summarization, and code generation.\n",
      "* **Agents and Tools:** LangChain's agent framework allows you to build applications where Gemini models can interact with external resources and tools (e.g., search engines, databases, APIs) to gather information and perform actions, extending their capabilities beyond simple text generation.\n",
      "* **Callbacks and Monitoring:** LangChain provides tools for monitoring the execution of your chains and agents, logging intermediate steps and performance metrics, which is crucial for debugging and optimization.\n",
      "\n",
      "**4. Community and Support:**\n",
      "\n",
      "* **Active Community:** LangChain has a large and active community, providing ample resources, tutorials, and support for developers working with Gemini and other LLMs.\n",
      "* **Rapid Development:** LangChain is constantly evolving, with new features and integrations being added regularly, ensuring you have access to the latest advancements in the field.\n",
      "\n",
      "**5. Cost Optimization (Potential):**\n",
      "\n",
      "* **Efficient Resource Utilization:** By managing the interaction with Gemini models, LangChain can potentially optimize resource usage and reduce costs by minimizing unnecessary API calls and maximizing the information extracted from each interaction.  However, this depends on implementation and usage patterns.\n",
      "\n",
      "\n",
      "By leveraging LangChain's features, developers can unlock the full potential of Gemini models and build more robust, efficient, and sophisticated language-powered applications.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "99d98d73-38bd-45a9-9681-664eca3a2839",
   "metadata": {},
   "source": [
    "# Strategy: Write clear instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab57e2-ce4e-47e1-855b-9d12f263bf15",
   "metadata": {},
   "source": [
    "These models can’t read your mind. If replies are too long, ask for shorter ones. If they’re too simple, request expert-level writing. If you dislike the format, show the one you prefer. The clearer you are, the better the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151e2c3-00f0-49fb-b9cf-ce48f2d4462f",
   "metadata": {},
   "source": [
    "### Tactic: Ask the model to adopt a persona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550724cf-3b74-4c7a-b965-8b26384c156a",
   "metadata": {},
   "source": [
    "The system message can be used to specify the persona used by the model in its replies."
   ]
  },
  {
   "cell_type": "code",
   "id": "8a8a8c80-3f3a-46c8-9f2a-9ea2a516dbea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:15:33.108684Z",
     "start_time": "2024-12-01T13:15:30.248965Z"
    }
   },
   "source": [
    "prompt = \"Write a poem for a sister's high school graduation\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tassel turns, a chapter's end,\n",
      "A journey shared, a faithful friend.\n",
      "Through teenage angst and triumphs bright,\n",
      "You've shone your own, unique, pure light.\n",
      "\n",
      "Remember scraped knees, whispered dreams,\n",
      "And secrets shared in sunlit streams?\n",
      "The silly fights, the laughter loud,\n",
      "A sister's bond, a precious shroud.\n",
      "\n",
      "Through late-night talks and early starts,\n",
      "You chased your dreams, played all your parts.\n",
      "With grit and grace, with strength and might,\n",
      "You conquered challenges, day and night.\n",
      "\n",
      "Now high school's walls begin to fade,\n",
      "A future vast, a path is laid.\n",
      "Go forth, dear sister, brave and bold,\n",
      "A story waiting to unfold.\n",
      "\n",
      "May all your hopes and wishes soar,\n",
      "And open doors await galore.\n",
      "Know that my love, unwavering, true,\n",
      "Will always be here, waiting for you.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a7fc9eff-583c-41e2-a81e-17390a06bc38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:16:01.568932Z",
     "start_time": "2024-12-01T13:16:00.044382Z"
    }
   },
   "source": [
    "prompt = \"\"\"Write a poem as Helena. Helena is 25 years old and an amazing writer. \n",
    "Her writing style is similar to famous 21st centry poet Rupi Kaur. \n",
    "Writing as Helena write a poem for her 18 year old sister to celebrate her sister's high scholl graduation.\n",
    "This will be read out to friends and family at the gathering\"\"\"\n",
    " \n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eighteen candles\n",
      "blown out\n",
      "a new chapter unfolds\n",
      "\n",
      "sister\n",
      "you bloomed\n",
      "through late night study sessions\n",
      "and early morning anxieties\n",
      "\n",
      "you conquered\n",
      "the mountain of tests\n",
      "the valleys of self-doubt\n",
      "\n",
      "now,\n",
      "stand tall\n",
      "on the precipice of your dreams\n",
      "the world waits\n",
      "for your next story\n",
      "\n",
      "i see a fire in you\n",
      "fierce and brilliant\n",
      "a flame that will light\n",
      "many paths\n",
      "\n",
      "go forth\n",
      "be brave\n",
      "be kind\n",
      "be you\n",
      "\n",
      "this is not an ending\n",
      "it's a beginning\n",
      "a promise whispered\n",
      "on the wind\n",
      "\n",
      "congratulations my love\n",
      "my sister\n",
      "my writer\n",
      "my friend\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "7f33d1dd-0c6c-4d00-8918-e9e87d4a1891",
   "metadata": {},
   "source": [
    "### Tactic: Use delimiters to clearly indicate distinct parts of the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2c192-e5f0-4933-bfe4-f342c48c13e2",
   "metadata": {},
   "source": [
    "Delimiters like triple quotation marks, XML tags, section titles, etc. can help demarcate sections of text to be treated differently."
   ]
  },
  {
   "cell_type": "code",
   "id": "580b0ff0-c029-4391-b425-d3b189b746a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:20:31.279320Z",
     "start_time": "2024-12-07T10:20:29.249138Z"
    }
   },
   "source": [
    "text = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \n",
    "singing. It's a beautiful day to go for a \n",
    "walk in the park. The flowers are blooming, and the  \n",
    "trees are swaying gently in the breeze. People \n",
    "are out and about, enjoying the lovely weather.  \n",
    "Some are having picnics, while others are playing \n",
    "games or simply relaxing on the grass. It's a \n",
    "perfect day to spend time outdoors and appreciate the \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"Summarize the text delimited by triple quotes with a haiku. '''{text}'''\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bright sun, birds all sing,\n",
      "Park blooms, gentle breeze caresses,\n",
      "Joy fills sunny day.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "214f5879-4e45-459b-9dee-421b98770f47",
   "metadata": {},
   "source": [
    "### Tactic: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c352af0b-544f-4437-90b6-70b0fd616486",
   "metadata": {},
   "source": [
    "Some tasks are best specified as a sequence of steps. Writing the steps out explicitly can make it easier for the model to follow them."
   ]
  },
  {
   "cell_type": "code",
   "id": "0027d895-6815-4b5c-8c93-506ead855f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:20:40.666452Z",
     "start_time": "2024-12-07T10:20:39.597787Z"
    }
   },
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"Use the following step-by-step instructions to respond to user inputs.\n",
    "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence \n",
    "         with a prefix that says \"Summary: \".\n",
    "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
    "'''{text}'''\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: In a charming village, siblings Jack and Jill's adventurous water-fetching quest ended with a tumble down a hill, but their spirits remained high.\n",
      "\n",
      "Translation: En un pueblo encantador, la aventura de los hermanos Jack y Jill para conseguir agua terminó con una caída por una colina, pero su ánimo permaneció alto.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "f3a83538-d764-4a6c-bb6f-b3f1fcc5a3c9",
   "metadata": {},
   "source": [
    "### Tactic: \"Few-shot\" prompting (or Provide examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724b706-a010-42ca-b50e-cb91f05543ae",
   "metadata": {},
   "source": [
    "The model is given a few examples within the prompt to help it understand the task. \n",
    "This is known as **\"few-shot\" prompting**."
   ]
  },
  {
   "cell_type": "code",
   "id": "82606799-fd00-4adf-9593-8b152302e092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:20:46.286950Z",
     "start_time": "2024-12-07T10:20:45.198250Z"
    }
   },
   "source": [
    "prompt = f\"\"\"Answer in a consistent style.\n",
    "q: Teach me about patience.\n",
    "a: The river that carves the deepest valley flows from a modest spring; the grandest symphony \n",
    "   originates from a single note; the most intricate tapestry begins with a solitary thread.\n",
    "q: Teach me about the ocean.\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  The ocean is a symphony of blue, a restless heart beating against the shores of continents.  It is a cradle of life, teeming with creatures both familiar and fantastical, from the smallest plankton to the largest whale.  It holds secrets in its deepest trenches, whispers stories in its crashing waves, and reflects the endless sky in its boundless expanse.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "554c643f-2e36-4b20-9e85-373751ab575d",
   "metadata": {},
   "source": [
    "### Tactic: Specify the desired length of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4fbc7-fbf7-453e-9034-3dd2162a0327",
   "metadata": {},
   "source": [
    "You can ask the model to create outputs of a specific length. You can specify the length in words, sentences, paragraphs, or bullet points. \n",
    "\n",
    "Note: the model is not very precise with word counts but is more reliable with paragraphs or bullet points."
   ]
  },
  {
   "cell_type": "code",
   "id": "9d0d9fe8-723e-47bc-96a4-26d223600470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:20:57.204358Z",
     "start_time": "2024-12-07T10:20:55.975956Z"
    }
   },
   "source": [
    "text = f\"\"\"So, they still had the 17 piece system on seasonal \n",
    "sale for around $49 in the month of November, about \n",
    "half off, but for some reason (call it price gouging) \n",
    "around the second week of December the prices all went \n",
    "up to about anywhere from between $70-$89 for the same \n",
    "system. And the 11 piece system went up around $10 or \n",
    "so in price also from the earlier sale price of $29. \n",
    "So it looks okay, but if you look at the base, the part \n",
    "where the blade locks into place doesn’t look as good \n",
    "as in previous editions from a few years ago, but I \n",
    "plan to be very gentle with it (example, I crush \n",
    "very hard items like beans, ice, rice, etc. in the  \n",
    "blender first then pulverize them in the serving size \n",
    "I want in the blender then switch to the whipping \n",
    "blade for a finer flour, and use the cross cutting blade \n",
    "first when making smoothies, then use the flat blade \n",
    "if I need them finer/less pulpy). Special tip when making \n",
    "smoothies, finely cut and freeze the fruits and \n",
    "vegetables (if using spinach-lightly stew soften the  \n",
    "spinach then freeze until ready for use-and if making \n",
    "sorbet, use a small to medium sized food processor) \n",
    "that you plan to use that way you can avoid adding so \n",
    "much ice if at all-when making your smoothie. \n",
    "After about a year, the motor was making a funny noise. \n",
    "I called customer service but the warranty expired \n",
    "already, so I had to buy another one. FYI: The overall \n",
    "quality has gone done in these types of products, so \n",
    "they are kind of counting on brand recognition and \n",
    "consumer loyalty to maintain sales. Got it in about \n",
    "two days.\"\"\"\n",
    "prompt = f\"\"\"Summarize the '''{text}''' delimited by triple quotes in about 50 words.\"\"\"\n",
    "\n",
    "answer = get_completion(prompt)\n",
    "print(answer)\n",
    "print(len(answer.split()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 17-piece kitchen system, initially half-price at $49, saw a significant price increase to $70-$89 in December.  Though functional, the build quality seems inferior to previous models.  After a year, the motor failed, highlighting declining product quality despite quick replacement shipping.  The author suggests careful use to prolong lifespan.\n",
      "\n",
      "49\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "4155e43f-cbf8-4843-a597-210bdbedccbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:21:03.610033Z",
     "start_time": "2024-12-07T10:21:01.910301Z"
    }
   },
   "source": [
    "prompt = f\"\"\"Summarize the '''{text}''' delimited by triple quotes in 2 paragraphs.\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 17-piece kitchen system was on sale for $49 in November but its price increased to $70-$89 in December.  Similarly, an 11-piece system saw a price increase.  While the system functioned, the build quality, specifically the blade locking mechanism, seemed inferior to previous versions.  The user offered tips for using the system to maximize its lifespan, including pre-processing hard ingredients and freezing smoothie ingredients.\n",
      "\n",
      "\n",
      "Despite careful use, the motor failed after a year, exceeding the warranty period.  The user attributed this to a decline in overall product quality and noted that the brand relies on its reputation to maintain sales. A replacement was received quickly.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "561a9f16-20bc-43a3-8d85-485094480ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:21:08.768438Z",
     "start_time": "2024-12-07T10:21:07.236434Z"
    }
   },
   "source": [
    "prompt = f\"\"\"Summarize the '''{text}''' delimited by triple quotes in 3 bullet points.\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* A 17-piece kitchen system was on sale for $49 in November, but its price increased to $70-$89 in December.  An 11-piece system also saw a price increase.\n",
      "\n",
      "* The reviewer notes a perceived decrease in quality compared to older models, specifically mentioning the blade locking mechanism.  They detail their careful usage techniques to prolong the appliance's life.\n",
      "\n",
      "* After a year, the motor failed, and the warranty had expired, necessitating a replacement purchase. The reviewer suggests declining product quality is driving sales through brand recognition and consumer loyalty.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "b6908e19-ce10-41d0-8e09-ff4b3d5db448",
   "metadata": {},
   "source": [
    "## Tactic: Ask for a structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73780a07-a25e-4491-b843-41f4f6338485",
   "metadata": {},
   "source": [
    "JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "id": "8aa2d0d2-0d1e-4aac-818e-d1c1cbdf7d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:21:15.736456Z",
     "start_time": "2024-12-07T10:21:14.028242Z"
    }
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"book_id\": \"1\",\n",
      "    \"title\": \"The Obsidian Mirror\",\n",
      "    \"author\": \"Lysandra Thorne\",\n",
      "    \"genre\": \"Fantasy\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"2\",\n",
      "    \"title\": \"Echoes of the Silent City\",\n",
      "    \"author\": \"Jasper Blackwood\",\n",
      "    \"genre\": \"Science Fiction\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"3\",\n",
      "    \"title\": \"The Clockwork Heart's Secret\",\n",
      "    \"author\": \"Seraphina Bellwether\",\n",
      "    \"genre\": \"Steampunk\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "b11c4163-2904-4b62-89a2-4ce6e169a327",
   "metadata": {},
   "source": [
    "## Tactic: Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "id": "4390c522-1d20-4e60-8094-90130335c254",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:21:28.550239Z",
     "start_time": "2024-12-07T10:21:24.498272Z"
    }
   },
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \n",
    "water boiling. While that's happening, \n",
    "grab a cup and put a tea bag in it. Once the water is \n",
    "hot enough, just pour it over the tea bag. \n",
    "Let it sit for a bit so the tea can steep. After a \n",
    "few minutes, take out the tea bag. If you \n",
    "like, you can add some sugar or milk to taste. \n",
    "And that's it! You've got yourself a delicious  \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "'''{text_1}'''\"\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - Add some sugar or milk to taste (optional).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "486a4b00-c00d-46b3-a53d-007aae52d040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:21:35.929870Z",
     "start_time": "2024-12-07T10:21:35.289762Z"
    }
   },
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \n",
    "singing. It's a beautiful day to go for a \n",
    "walk in the park. The flowers are blooming, and the \n",
    "trees are swaying gently in the breeze. People \n",
    "are out and about, enjoying the lovely weather. \n",
    "Some are having picnics, while others are playing \n",
    "games or simply relaxing on the grass. It's a \n",
    "perfect day to spend time outdoors and appreciate the \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "'''{text_2}'''\"\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No steps provided.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb36d-fd49-4406-a833-6322df252e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
